{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1999193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce31a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_root = Path(\"..\").resolve()\n",
    "data_dir = project_root / \"data\"\n",
    "labels_path = data_dir / \"labels.csv\"\n",
    "dataset_dir = data_dir / \"fashion_dataset\"\n",
    "deepfashion_dir = data_dir / \"fashion_dataset\" / \"DeepFashion2\"\n",
    "fashion_dataset_dir = dataset_dir / 'FashionDataset'\n",
    "csv_dir = deepfashion_dir / \"img_info_dataframes\"\n",
    "\n",
    "# Load filtered CSVs\n",
    "train_df = pd.read_csv(csv_dir / \"train.csv\")\n",
    "val_df = pd.read_csv(csv_dir / \"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdf54745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv created: (112174, 5)\n",
      "         filename     group         subcategory  split  \\\n",
      "38666  073252.jpg  Clothing               skirt  train   \n",
      "87916  034737.jpg  Clothing               skirt  train   \n",
      "51018  175592.jpg  Clothing  short sleeve dress  train   \n",
      "18958  079150.jpg  Clothing               skirt  train   \n",
      "76346  110583.jpg  Clothing          vest dress  train   \n",
      "\n",
      "                                                filepath  \n",
      "38666  /Users/hossein/Desktop/School/deep_learning_TD...  \n",
      "87916  /Users/hossein/Desktop/School/deep_learning_TD...  \n",
      "51018  /Users/hossein/Desktop/School/deep_learning_TD...  \n",
      "18958  /Users/hossein/Desktop/School/deep_learning_TD...  \n",
      "76346  /Users/hossein/Desktop/School/deep_learning_TD...  \n"
     ]
    }
   ],
   "source": [
    "csv_dir = deepfashion_dir / \"img_info_dataframes\"\n",
    "image_root = deepfashion_dir / \"deepfashion2_original_images\"\n",
    "\n",
    "train_df = pd.read_csv(csv_dir / \"train.csv\")\n",
    "val_df = pd.read_csv(csv_dir / \"validation.csv\")\n",
    "\n",
    "# Define the 9 target subcategories\n",
    "target_subcategories = {\n",
    "    'long sleeve dress', 'short sleeve dress', 'sling dress', 'vest dress',  # Dresses\n",
    "    'skirt',                                                                 # Skirt\n",
    "    'long sleeve outwear', 'short sleeve outwear'                            # Outerwear\n",
    "}\n",
    "\n",
    "subcategory_col = \"category_name\"\n",
    "\n",
    "# Filter datasets\n",
    "filtered_train = train_df[train_df[subcategory_col].isin(target_subcategories)]\n",
    "filtered_val = val_df[val_df[subcategory_col].isin(target_subcategories)]\n",
    "\n",
    "# Map subcategories to group categories\n",
    "subcat_to_group = {\n",
    "    'long sleeve dress': 'Clothing',\n",
    "    'short sleeve dress': 'Clothing',\n",
    "    'sling dress': 'Clothing',\n",
    "    'vest dress': 'Clothing',\n",
    "    'skirt': 'Clothing',\n",
    "    'long sleeve outwear': 'Clothing',\n",
    "    'short sleeve outwear': 'Clothing',\n",
    "}\n",
    "\n",
    "def process_split(df, split):\n",
    "    df = df.copy()\n",
    "    df[\"group\"] = df[subcategory_col].map(subcat_to_group)\n",
    "    df[\"subcategory\"] = df[subcategory_col]\n",
    "    df[\"split\"] = split\n",
    "    df[\"filename\"] = df[\"path\"].apply(lambda x: Path(x).name)\n",
    "    df[\"filepath\"] = df[\"filename\"].apply(\n",
    "        lambda x: str((dataset_dir / \"DeepFashion2\" / \"deepfashion2_original_images\" / split / \"image\" / x).resolve())\n",
    "    )\n",
    "    return df[[\"filename\", \"group\", \"subcategory\", \"split\", \"filepath\"]]\n",
    "\n",
    "final_df = pd.concat([\n",
    "    process_split(filtered_train, \"train\"),\n",
    "    process_split(filtered_val, \"validation\")\n",
    "], ignore_index=True)\n",
    "\n",
    "final_df.to_csv(labels_path, index=False)\n",
    "print(\"labels.csv created:\", final_df.shape)\n",
    "print(final_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712edad3",
   "metadata": {},
   "source": [
    "### ADD Bags & Shoes FROM fashion-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca365161",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = fashion_dataset_dir / \"images\"\n",
    "styles_csv_path = fashion_dataset_dir / \"styles.csv\"\n",
    "\n",
    "styles_df = pd.read_csv(styles_csv_path, on_bad_lines=\"skip\")\n",
    "styles_df = styles_df.dropna(subset=[\"articleType\", \"id\"])\n",
    "\n",
    "articletype_to_slowfashion = {\n",
    "    \"Heels\": (\"Shoes\", \"High Heels\"),\n",
    "    \"Boots\": (\"Shoes\", \"Boots\"),\n",
    "    \"Flats\": (\"Shoes\", \"Flats\"),\n",
    "    \"Clutches\": (\"Bags\", \"Clutches\"),\n",
    "    \"Handbags\": (\"Bags\", \"Shoulder Bags\"),\n",
    "}\n",
    "\n",
    "# Filter styles based on valid articleTypes\n",
    "filtered_styles = styles_df[styles_df[\"articleType\"].isin(articletype_to_slowfashion.keys())].copy()\n",
    "\n",
    "filtered_styles[\"group\"] = filtered_styles[\"articleType\"].map(lambda x: articletype_to_slowfashion[x][0])\n",
    "filtered_styles[\"subcategory\"] = filtered_styles[\"articleType\"].map(lambda x: articletype_to_slowfashion[x][1])\n",
    "filtered_styles[\"filename\"] = filtered_styles[\"id\"].astype(str) + \".jpg\"\n",
    "filtered_styles[\"split\"] = \"fashion_extra\"\n",
    "filtered_styles[\"filepath\"] = filtered_styles[\"filename\"].apply(lambda x: str(dataset_dir / \"FashionDataset\" / \"images\" / x))\n",
    "\n",
    "fashion_df = filtered_styles[[\"filename\", \"group\", \"subcategory\", \"split\", \"filepath\"]]\n",
    "\n",
    "# Combine with DeepFashion2 clothing data\n",
    "final_combined_df = pd.concat([final_df, fashion_df], ignore_index=True)\n",
    "# final_combined_df = final_df.copy()\n",
    "final_combined_df.to_csv(labels_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f24a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned labels.csv and df_encoded.csv saved: (116046, 5)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing files\n",
    "from pathlib import Path\n",
    "\n",
    "def file_exists(path):\n",
    "    try:\n",
    "        abs_path = (project_root / path).resolve()\n",
    "        return abs_path.exists()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "final_combined_df = final_combined_df[final_combined_df[\"filepath\"].apply(file_exists)]\n",
    "\n",
    "# Save clean files\n",
    "final_combined_df.to_csv(labels_path, index=False)\n",
    "final_combined_df.to_csv(data_dir / \"df_encoded.csv\", index=False)\n",
    "\n",
    "print(\"Final cleaned labels.csv and df_encoded.csv saved:\", final_combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2944c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116046"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05e31941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      " subcategory\n",
      "skirt                   37357\n",
      "vest dress              21301\n",
      "short sleeve dress      20338\n",
      "long sleeve outwear     15468\n",
      "long sleeve dress        9384\n",
      "sling dress              7641\n",
      "Shoulder Bags            1759\n",
      "High Heels               1323\n",
      "short sleeve outwear      685\n",
      "Flats                     500\n",
      "Clutches                  290\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution:\\n\", final_combined_df[\"subcategory\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved: /Users/hossein/Desktop/School/deep_learning_TDIS22/hierarchical-image-classification/data/df_balanced_1000.csv\n",
      "Class distribution:\n",
      " subcategory\n",
      "High Heels              1000\n",
      "Shoulder Bags           1000\n",
      "long sleeve dress       1000\n",
      "long sleeve outwear     1000\n",
      "short sleeve dress      1000\n",
      "skirt                   1000\n",
      "sling dress             1000\n",
      "vest dress              1000\n",
      "short sleeve outwear     685\n",
      "Flats                    500\n",
      "Clutches                 290\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/xs98p9sd6y3_rkdt0nrtqsb00000gn/T/ipykernel_18384/1465866122.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = df.groupby(\"subcategory\").apply(\n"
     ]
    }
   ],
   "source": [
    "# Load original full dataset\n",
    "df = pd.read_csv(data_dir / \"df_encoded.csv\")\n",
    "\n",
    "# Determine max per class\n",
    "max_per_class = 1000\n",
    "\n",
    "# Sample max_per_class rows per class (or all if fewer exist)\n",
    "balanced_df = df.groupby(\"subcategory\").apply(\n",
    "    lambda x: x.sample(n=min(len(x), max_per_class), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Save new balanced version\n",
    "balanced_path = data_dir / \"df_balanced.csv\"\n",
    "balanced_df.to_csv(balanced_path, index=False)\n",
    "\n",
    "print(f\"Balanced dataset saved: {balanced_path}\")\n",
    "print(\"Class distribution:\\n\", balanced_df[\"subcategory\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL Assignment (Python 3.10)",
   "language": "python",
   "name": "dl-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
